---
title: 什么是 LLM 微调技术?
description: 什么是 LLM 微调技术?

date: 20250208
plainLanguage: |
  **LLM 微调说白了就是：** 给通用 AI 模型"上培训班"，让它在某个专业领域更牛。

  就像你从大学毕业，学了很多基础知识，但要进医院当医生，还得接受专业培训。微调就是给 AI 也上这样的"专业培训班"。

  **用大白话说：**
  想象你会做基本的家常菜（预训练模型），但想开川菜馆，就得专门学川菜的做法（微调）。你不用从切菜、炒菜这些基础学起，只需要学川菜的特色做法（麻辣、花椒等），很快就能上手。

  **微调流程：**
  1. **选基础模型**：找个已经训练好的通用模型（比如 GPT、Qwen）
  2. **准备专业数据**：收集你想让它擅长的领域的资料（医疗、法律等）
  3. **小步训练**：用这些专业资料继续训练模型，但步子要小（学习率低）
  4. **测试调整**：看效果，不好就再调整

  **好处：**
  - 省时省钱：比从头训练快多了
  - 效果好：在专业领域表现更好
  - 灵活：可以针对不同任务定制

  **缺点：**
  - **过拟合**：太专注某个领域，可能在其他领域变傻
  - **需要专业知识**：得知道怎么准备数据、怎么评估效果

  说白了，微调就是"让通才变专才"的过程——不是从头培养，而是在已有基础上加强某个方向。
---




![](/assets/images/llm-fine-tuning.png)

LLM 微调 (Fine-tuning) 是一种通过特定领域数据对预训练语言模型进行二次训练的技术。目的是在保持模型通用语言理解能力的基础上，使其适应特定任务或领域。

通过微调技术，基础模型可以显著提升在目标领域（如医疗、法律、金融等）的表现。


## 微调过程

典型微调流程包括以下步骤：
- 选择基础模型：使用预训练好的通用语言模型（如 Qwen、LLaMA 等）作为起点
- 准备领域数据：收集与目标领域相关的标注数据集
- 调整超参数(Hyperparameters)：设置合适的学习率、训练轮次等参数（通常比预训练时更小, 这些都是超参数）
- 领域适应训练：在保持原有参数的基础上，用领域数据继续训练模型
- 评估验证：通过领域特定的评估指标检验微调效果
- 迭代上述过程来获得更好的结果直到满意

## 微调的优点

- 显著提升特定任务/领域表现
- 数据效率高（相比从头训练）
- 计算资源需求相对较少
- 灵活性高（可针对不同场景定制）

## 微调可能存在的问题

- 过拟合风险：过度适配训练数据可能导致泛化能力下降
- 领域依赖：在非目标领域表现可能下降
- 需要领域专业知识：数据准备和评估指标设计需要领域知识
- 计算资源需求：虽然比预训练少，但仍需要可观资源



## 题外话

推荐阅读 ULMFiT 论文（首次提出 NLP 三阶段微调框架）和 BERT 论文的微调章节，这两个工作奠定了现代语言模型微调的基础方法论。


## Refs

- [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)
- [The Ultimate Guide to LLM Fine Tuning: Best Practices & Tools](https://www.lakera.ai/blog/llm-fine-tuning-guide)
- [Fine-tuning vs Prompt Engineering](https://mlops.community/fine-tuning-vs-prompt-engineering-llms/)
