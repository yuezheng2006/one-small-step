---
title: 什么是 LLM 蒸馏技术?
description: 什么是 LLM 蒸馏技术?

date: 20250123
plainLanguage: |
  **LLM 蒸馏说白了就是：** 让"大师傅"教"小徒弟"，让小徒弟学会大师傅的本事。

  就像武侠小说里，高手把自己的内力传给徒弟。蒸馏就是让大模型把"知识"传给小模型，让小模型也能干得差不多。

  **用大白话说：**
  想象一个米其林三星厨师（大模型），他做菜很厉害但很贵很慢。现在让他教个学徒（小模型），学徒学会后，虽然做得没师傅那么好，但也有 90 分了，而且便宜快速。

  **蒸馏流程：**
  1. **训练大师傅**：先训练一个超强的大模型（教师模型）
  2. **大师傅示范**：让大模型预测一些问题，记录下它的"思考过程"（概率分布）
  3. **小徒弟学习**：让小模型学习大模型的"思考过程"，而不只是学标准答案

  **关键概念：**
  - **硬标签（hard targets）**：标准答案，比如"这是只猫"
  - **软标签（soft targets）**：大模型的概率，比如"90% 是猫，8% 是狗，2% 是狐狸"
  - 小模型学的是软标签，包含了更多信息

  **好处：**
  - 小模型体积小、速度快、省资源
  - 效果接近大模型（通常 90%-95%）
  - 可以部署到手机、边缘设备

  **缺点：**
  - 总会损失一些能力
  - 依赖大模型的质量（大模型错了，小模型也错）

  说白了，蒸馏就是"师傅带徒弟"的 AI 版本——让小模型站在巨人的肩膀上，用更少的资源做差不多的事。
---




![](/assets/images/knowledge-distill.png)

LLM 蒸馏 (Distillation) 是一种技术，用于将大型语言模型 (LLM) 的知识转移到较小的模型中。其主要目的是在保持模型性能的同时，减少模型的大小和计算资源需求。通过蒸馏技术，较小的模型可以在推理时更高效地运行，适用于资源受限的环境。


## 蒸馏过程

蒸馏过程通常包括以下几个步骤：
- 训练教师模型：首先训练一个大型且性能优越的教师模型。
- 生成软标签：使用教师模型对训练数据进行预测，生成软目标 (soft targets) ，这些目标包含了教师模型的概率分布信息。
- 训练学生模型：使用软目标 (soft targets) 和原始训练数据 (hard targets) 来训练较小的学生模型，使其能够模仿教师模型的行为。
这种方法不仅可以提高模型的效率，还可以在某些情况下提高模型的泛化能力。

## 蒸馏的优点

- 减少模型大小和计算资源需求
- 增加推理速度
- 易于访问和部署

(其实就是小模型相对于大模型的优点)

## 蒸馏可能存在的问题

- 信息丢失：由于学生模型比教师模型小，可能无法完全捕捉教师模型的所有知识和细节，导致信息丢失。
- 依赖教师模型：学生模型的性能高度依赖于教师模型的质量，如果教师模型本身存在偏差或错误，学生模型可能会继承这些问题。
- 适用性限制：蒸馏技术可能不适用于所有类型的模型或任务，尤其是那些需要高精度和复杂推理的任务。

## 典型例子

- GPT-4o  (教师模型) 中提炼出 GPT-4o-mini  (学生模型) 
- DeepSeek-R1  (教师模型) 中提炼出 DeepSeek-R1-Distill-Qwen-32B  (学生模型) (这个不是传统意义上的蒸馏了, 是蒸馏+数据增强+微调)

## 其他蒸馏技术

- 数据增强: 使用教师模型生成额外的训练数据。通过创建更大、更具包容性的数据集，学生可以接触到更广泛的场景和示例，从而提高其泛化性能。
- 中间层蒸馏: 将知识从教师模型的中间层转移到学生。通过学习这些中间表示，学生可以捕获更详细和结构化的信息，从而获得更好的整体表现。
- 多教师蒸馏: 通过汇总不同教师模型的知识，学生模型可以实现更全面的理解并提高稳健性，因为它整合了不同的观点和见解。


## 题外话

强烈推荐读一下下面引用中的第一个和第二个论文, 里面有详细的蒸馏技术介绍. 第二个论文是 Geoffrey Hinton 写的, 他正式在这篇论文里面首次引入了 soft targets 和 hard targets 的概念.


## Refs

- [Knowledge Distillation: A Survey](https://arxiv.org/pdf/2006.05525)
- [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531)
- [LLM Distillation Explained: Applications, Implementation & More](https://www.datacamp.com/blog/distillation-llm)
